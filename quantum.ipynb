{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 퀀텀 AI 대회 '칸쵸' 팀 - 모델 재현 노트북\n",
        "\n",
        "본 노트북은 `best_model.pth` 모델 가중치 파일을 로드하여 최고 점수를 재현하는 데 사용됩니다.\n",
        "\n",
        "**실행 전 확인:**\n",
        "1. `pip install -r requirements.txt`로 모든 의존성을 설치했는지 확인하세요.\n",
        "2. `best_model.pth` 파일이 이 노트북과 동일한 디렉토리에 있는지 확인하세요."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. 의존성 및 설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 라이브러리 임포트\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pennylane as qml\n",
        "\n",
        "import os\n",
        "import random\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# 경로 설정\n",
        "base_path = os.path.join(os.getcwd(), 'output')\n",
        "os.makedirs(base_path, exist_ok=True)\n",
        "\n",
        "# 난수 고정\n",
        "SEED = 3006\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "# device 설정\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. 양자 회로 정의"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 큐비트 기반 양자 회로 정의\n",
        "dev = qml.device(\"default.qubit\", wires=6)\n",
        "\n",
        "@qml.qnode(dev, interface=\"torch\")\n",
        "def quantum_circuit(inputs, weights):\n",
        "    num_qubits = 6\n",
        "    layers = 3\n",
        "    qml.AngleEmbedding(inputs, wires=range(num_qubits))\n",
        "    for l in range(layers):\n",
        "        for i in range(num_qubits):\n",
        "            qml.RX(weights[(l * num_qubits + i) % weights.shape[0]], wires=i)\n",
        "        for i in range(0, num_qubits, 2):\n",
        "            if i + 1 < num_qubits:\n",
        "                qml.CNOT(wires=[i, i+1])\n",
        "    for i in range(num_qubits):\n",
        "        qml.RZ(weights[(i + weights.shape[0] // 2) % weights.shape[0]], wires=i)\n",
        "    return [qml.expval(qml.PauliZ(i)) for i in range(num_qubits)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. 데이터 준비"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 데이터 변환 정의\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "\n",
        "# 데이터셋 로드\n",
        "test_ds = datasets.FashionMNIST(root=base_path, train=False, download=True, transform=transform_test)\n",
        "\n",
        "# 0과 6만 필터링\n",
        "test_mask  = (test_ds.targets  == 0) | (test_ds.targets  == 6)\n",
        "test_idx   = torch.where(test_mask)[0]\n",
        "\n",
        "# 레이블 이진화\n",
        "test_ds.targets[ test_ds.targets  == 6] = 1\n",
        "\n",
        "# 0과 6만 포함된 데이터셋\n",
        "binary_test_ds  = Subset(test_ds,  test_idx)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. 모델 정의"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CNN + 양자 회로 + MLP 통합 모델\n",
        "class HybridModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 16, kernel_size=5, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(16)\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=4, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(32)\n",
        "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(64)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc1 = nn.Linear(64, 6)\n",
        "        self.norm = nn.LayerNorm(6)\n",
        "        self.q_params = nn.Parameter(torch.rand(30))\n",
        "        self.fc2 = nn.Linear(6, 32)\n",
        "        self.fc3 = nn.Linear(32, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = self.pool(x)\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = self.pool(x)\n",
        "        x = F.relu(self.bn3(self.conv3(x)))\n",
        "        x = self.pool(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc1(x)\n",
        "        x = self.norm(x)\n",
        "        q_out = quantum_circuit(x, self.q_params)\n",
        "        q_out = torch.stack(list(q_out), dim=1).to(torch.float32)\n",
        "        x = self.fc2(q_out)\n",
        "        x = self.fc3(x)\n",
        "        return F.log_softmax(x, dim=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. 모델 스펙 검사"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# QNN 구조 및 파라미터 사양 확인\n",
        "temp_model = HybridModel()\n",
        "temp_model.eval()\n",
        "\n",
        "input_sample = torch.randn(1, 6)\n",
        "q_weight_sample = temp_model.q_params.data\n",
        "qc_info = qml.specs(quantum_circuit)(input_sample, q_weight_sample)\n",
        "\n",
        "# 스펙 제한 조건 확인\n",
        "if qc_info[\"num_tape_wires\"] > 8:\n",
        "    raise ValueError(\"❌ 큐비트 수 초과\")\n",
        "if qc_info[\"resources\"].depth > 30:\n",
        "    raise ValueError(\"❌ 회로 깊이 초과\")\n",
        "if qc_info[\"num_trainable_params\"] > 60:\n",
        "    raise ValueError(\"❌ 학습 가능한 파라미터 수 초과\")\n",
        "print(\"✅ QNN 회로 스펙 체크 완료\")\n",
        "\n",
        "# 전체 학습 파라미터 수 체크\n",
        "trainable_count = sum(param.numel() for param in temp_model.parameters() if param.requires_grad)\n",
        "if trainable_count > 50000:\n",
        "    raise ValueError(f\"❌ 파라미터 수 초과: {trainable_count}\")\n",
        "print(f\"✅ 전체 파라미터 수 검증 통과: {trainable_count}\")\n",
        "del temp_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. 모델 로드 및 정확도 재현"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 로컬 경로에서 모델 파라미터 로드\n",
        "model_path = \"best_model_seed_3006.pth\"\n",
        "\n",
        "if not os.path.exists(model_path):\n",
        "    print(f\"❗️ {model_path} 파일이 없습니다. 리포지토리에서 파일을 다운로드 받아주세요.\")\n",
        "else:\n",
        "    best_model = HybridModel().to(device)\n",
        "    # map_location을 통해 현재 설정된 device로 모델을 로드합니다.\n",
        "    best_model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "    print(f\"✅ 모델 파라미터 업로드 완료! ({model_path})\")\n",
        "\n",
        "    # 테스트 데이터 로더 생성\n",
        "    test_loader  = DataLoader(binary_test_ds,  batch_size=64, shuffle=False, num_workers=0, pin_memory=True)\n",
        "\n",
        "    # 평가 시작\n",
        "    best_model.eval()\n",
        "    test_correct, test_total = 0, 0\n",
        "    all_preds = []\n",
        "    with torch.no_grad():\n",
        "        for imgs, lbls in test_loader:\n",
        "            # 원본 코드의 오류 수정: lbls도 device로 이동해야 합니다.\n",
        "            imgs, lbls = imgs.to(device), lbls.to(device)\n",
        "            \n",
        "            out = best_model(imgs)\n",
        "            pred = out.argmax(dim=1)\n",
        "            test_correct += (pred == lbls).sum().item()\n",
        "            test_total += lbls.size(0)\n",
        "            all_preds.extend(pred.cpu().numpy())\n",
        "\n",
        "    test_acc = test_correct / test_total * 100\n",
        "    print(\"=\"*40)\n",
        "    print(f\"🎯 최종 재현 정확도 (0/6) = {test_acc:.4f}%\")\n",
        "    print(\"=\"*40)\n",
        "\n",
        "    # (선택 사항) 제출 파일 생성 로직\n",
        "    best_preds = [0 if p == 0 else 6 for p in all_preds]\n",
        "    y_pred_full = np.zeros(len(test_ds), dtype=int)\n",
        "    y_pred_full[test_idx] = best_preds\n",
        "    print(f\"전체 테스트셋 대상 예측 생성 완료 (길이: {len(y_pred_full)})\")\n",
        "\n",
        "    # df = pd.DataFrame({\"y_pred\": y_pred_full})\n",
        "    # csv_name = os.path.join(base_path, f\"y_pred_{SEED}_reproduce.csv\")\n",
        "    # df.to_csv(csv_name, index=False, header=False)\n",
        "    # print(f\"제출 파일 저장 완료: {csv_name}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## [부록] 모델 학습 코드 (참고용)\n",
        "\n",
        "아래는 `best_model.pth` 파일을 생성하는 데 사용된 학습 코드입니다. (원본 노트북 기준 주석 처리된 부분)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### A. 학습용 데이터 준비 (원본)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# # 데이터 변환 정의\n",
        "# transform_train = transforms.Compose([\n",
        "#     transforms.RandomRotation(15),\n",
        "#     transforms.RandomHorizontalFlip(),\n",
        "#     transforms.ToTensor(),\n",
        "#     transforms.Normalize((0.1307,), (0.3081,))\n",
        "# ])\n",
        "# transform_test = transforms.Compose([\n",
        "#     transforms.ToTensor(),\n",
        "#     transforms.Normalize((0.1307,), (0.3081,))\n",
        "# ])\n",
        "\n",
        "# # 데이터셋 로드\n",
        "# train_ds = datasets.FashionMNIST(root=base_path, train=True, download=True, transform=transform_train)\n",
        "# test_ds = datasets.FashionMNIST(root=base_path, train=False, download=True, transform=transform_test)\n",
        "\n",
        "# # 0과 6만 필터링\n",
        "# train_mask = (train_ds.targets == 0) | (train_ds.targets == 6)\n",
        "# test_mask  = (test_ds.targets  == 0) | (test_ds.targets  == 6)\n",
        "# train_idx  = torch.where(train_mask)[0]\n",
        "# test_idx   = torch.where(test_mask)[0]\n",
        "\n",
        "# # 레이블 이진화\n",
        "# train_ds.targets[train_ds.targets == 6] = 1\n",
        "# test_ds.targets[ test_ds.targets  == 6] = 1\n",
        "\n",
        "# # 0과 6만 포함된 데이터셋\n",
        "# binary_train_ds = Subset(train_ds, train_idx)\n",
        "# binary_test_ds  = Subset(test_ds,  test_idx)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### B. 학습 루프 (원본)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# # 데이터 로더 설정\n",
        "# train_loader = DataLoader(binary_train_ds, batch_size=64, shuffle=True,  num_workers=0, pin_memory=True)\n",
        "# test_loader  = DataLoader(binary_test_ds,  batch_size=64, shuffle=False, num_workers=0, pin_memory=True)\n",
        "\n",
        "# # 모델·옵티마이저·스케줄러·손실함수 설정\n",
        "# model = HybridModel().to(device)\n",
        "# optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
        "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=10, factor=0.2)\n",
        "# criterion = nn.NLLLoss()\n",
        "\n",
        "# best_acc, epochs_no_improve = 0.0, 0\n",
        "# early_stopping_patience = 70\n",
        "# best_model_path   = os.path.join(base_path, f'best_model_seed_{SEED}.pth')\n",
        "\n",
        "# for epoch in range(800):\n",
        "#     model.train()\n",
        "#     total_loss, correct, total = 0, 0, 0\n",
        "#     for imgs, lbls in train_loader:\n",
        "#         imgs, lbls = imgs.to(device), lbls.to(device)\n",
        "#         optimizer.zero_grad()\n",
        "#         out = model(imgs)\n",
        "#         loss = criterion(out, lbls)\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "#         total_loss += loss.item()\n",
        "#         preds = out.argmax(dim=1)\n",
        "#         correct += (preds == lbls).sum().item()\n",
        "#         total += lbls.size(0)\n",
        "#     train_acc = correct / total\n",
        "#     scheduler.step(train_acc)\n",
        "#     if train_acc > best_acc:\n",
        "#         best_acc = train_acc\n",
        "#         epochs_no_improve = 0\n",
        "#         torch.save(model.state_dict(), best_model_path)\n",
        "#     else:\n",
        "#         epochs_no_improve += 1\n",
        "#         if epochs_no_improve >= early_stopping_patience:\n",
        "#             break\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
