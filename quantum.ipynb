{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# í€€í…€ AI ëŒ€íšŒ 'ì¹¸ìµ¸' íŒ€ - ëª¨ë¸ ì¬í˜„ ë…¸íŠ¸ë¶\n",
        "\n",
        "ë³¸ ë…¸íŠ¸ë¶ì€ `best_model.pth` ëª¨ë¸ ê°€ì¤‘ì¹˜ íŒŒì¼ì„ ë¡œë“œí•˜ì—¬ ìµœê³  ì ìˆ˜ë¥¼ ì¬í˜„í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤.\n",
        "\n",
        "**ì‹¤í–‰ ì „ í™•ì¸:**\n",
        "1. `pip install -r requirements.txt`ë¡œ ëª¨ë“  ì˜ì¡´ì„±ì„ ì„¤ì¹˜í–ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.\n",
        "2. `best_model.pth` íŒŒì¼ì´ ì´ ë…¸íŠ¸ë¶ê³¼ ë™ì¼í•œ ë””ë ‰í† ë¦¬ì— ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. ì˜ì¡´ì„± ë° ì„¤ì •"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pennylane as qml\n",
        "\n",
        "import os\n",
        "import random\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# ê²½ë¡œ ì„¤ì •\n",
        "base_path = os.path.join(os.getcwd(), 'output')\n",
        "os.makedirs(base_path, exist_ok=True)\n",
        "\n",
        "# ë‚œìˆ˜ ê³ ì •\n",
        "SEED = 3006\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "# device ì„¤ì •\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. ì–‘ì íšŒë¡œ ì •ì˜"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# íë¹„íŠ¸ ê¸°ë°˜ ì–‘ì íšŒë¡œ ì •ì˜\n",
        "dev = qml.device(\"default.qubit\", wires=6)\n",
        "\n",
        "@qml.qnode(dev, interface=\"torch\")\n",
        "def quantum_circuit(inputs, weights):\n",
        "    num_qubits = 6\n",
        "    layers = 3\n",
        "    qml.AngleEmbedding(inputs, wires=range(num_qubits))\n",
        "    for l in range(layers):\n",
        "        for i in range(num_qubits):\n",
        "            qml.RX(weights[(l * num_qubits + i) % weights.shape[0]], wires=i)\n",
        "        for i in range(0, num_qubits, 2):\n",
        "            if i + 1 < num_qubits:\n",
        "                qml.CNOT(wires=[i, i+1])\n",
        "    for i in range(num_qubits):\n",
        "        qml.RZ(weights[(i + weights.shape[0] // 2) % weights.shape[0]], wires=i)\n",
        "    return [qml.expval(qml.PauliZ(i)) for i in range(num_qubits)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. ë°ì´í„° ì¤€ë¹„"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ë°ì´í„° ë³€í™˜ ì •ì˜\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "\n",
        "# ë°ì´í„°ì…‹ ë¡œë“œ\n",
        "test_ds = datasets.FashionMNIST(root=base_path, train=False, download=True, transform=transform_test)\n",
        "\n",
        "# 0ê³¼ 6ë§Œ í•„í„°ë§\n",
        "test_mask  = (test_ds.targets  == 0) | (test_ds.targets  == 6)\n",
        "test_idx   = torch.where(test_mask)[0]\n",
        "\n",
        "# ë ˆì´ë¸” ì´ì§„í™”\n",
        "test_ds.targets[ test_ds.targets  == 6] = 1\n",
        "\n",
        "# 0ê³¼ 6ë§Œ í¬í•¨ëœ ë°ì´í„°ì…‹\n",
        "binary_test_ds  = Subset(test_ds,  test_idx)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. ëª¨ë¸ ì •ì˜"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CNN + ì–‘ì íšŒë¡œ + MLP í†µí•© ëª¨ë¸\n",
        "class HybridModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 16, kernel_size=5, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(16)\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=4, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(32)\n",
        "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(64)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc1 = nn.Linear(64, 6)\n",
        "        self.norm = nn.LayerNorm(6)\n",
        "        self.q_params = nn.Parameter(torch.rand(30))\n",
        "        self.fc2 = nn.Linear(6, 32)\n",
        "        self.fc3 = nn.Linear(32, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = self.pool(x)\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = self.pool(x)\n",
        "        x = F.relu(self.bn3(self.conv3(x)))\n",
        "        x = self.pool(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc1(x)\n",
        "        x = self.norm(x)\n",
        "        q_out = quantum_circuit(x, self.q_params)\n",
        "        q_out = torch.stack(list(q_out), dim=1).to(torch.float32)\n",
        "        x = self.fc2(q_out)\n",
        "        x = self.fc3(x)\n",
        "        return F.log_softmax(x, dim=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. ëª¨ë¸ ìŠ¤í™ ê²€ì‚¬"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# QNN êµ¬ì¡° ë° íŒŒë¼ë¯¸í„° ì‚¬ì–‘ í™•ì¸\n",
        "temp_model = HybridModel()\n",
        "temp_model.eval()\n",
        "\n",
        "input_sample = torch.randn(1, 6)\n",
        "q_weight_sample = temp_model.q_params.data\n",
        "qc_info = qml.specs(quantum_circuit)(input_sample, q_weight_sample)\n",
        "\n",
        "# ìŠ¤í™ ì œí•œ ì¡°ê±´ í™•ì¸\n",
        "if qc_info[\"num_tape_wires\"] > 8:\n",
        "    raise ValueError(\"âŒ íë¹„íŠ¸ ìˆ˜ ì´ˆê³¼\")\n",
        "if qc_info[\"resources\"].depth > 30:\n",
        "    raise ValueError(\"âŒ íšŒë¡œ ê¹Šì´ ì´ˆê³¼\")\n",
        "if qc_info[\"num_trainable_params\"] > 60:\n",
        "    raise ValueError(\"âŒ í•™ìŠµ ê°€ëŠ¥í•œ íŒŒë¼ë¯¸í„° ìˆ˜ ì´ˆê³¼\")\n",
        "print(\"âœ… QNN íšŒë¡œ ìŠ¤í™ ì²´í¬ ì™„ë£Œ\")\n",
        "\n",
        "# ì „ì²´ í•™ìŠµ íŒŒë¼ë¯¸í„° ìˆ˜ ì²´í¬\n",
        "trainable_count = sum(param.numel() for param in temp_model.parameters() if param.requires_grad)\n",
        "if trainable_count > 50000:\n",
        "    raise ValueError(f\"âŒ íŒŒë¼ë¯¸í„° ìˆ˜ ì´ˆê³¼: {trainable_count}\")\n",
        "print(f\"âœ… ì „ì²´ íŒŒë¼ë¯¸í„° ìˆ˜ ê²€ì¦ í†µê³¼: {trainable_count}\")\n",
        "del temp_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. ëª¨ë¸ ë¡œë“œ ë° ì •í™•ë„ ì¬í˜„"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ë¡œì»¬ ê²½ë¡œì—ì„œ ëª¨ë¸ íŒŒë¼ë¯¸í„° ë¡œë“œ\n",
        "model_path = \"best_model_seed_3006.pth\"\n",
        "\n",
        "if not os.path.exists(model_path):\n",
        "    print(f\"â—ï¸ {model_path} íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ë¦¬í¬ì§€í† ë¦¬ì—ì„œ íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œ ë°›ì•„ì£¼ì„¸ìš”.\")\n",
        "else:\n",
        "    best_model = HybridModel().to(device)\n",
        "    # map_locationì„ í†µí•´ í˜„ì¬ ì„¤ì •ëœ deviceë¡œ ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤.\n",
        "    best_model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "    print(f\"âœ… ëª¨ë¸ íŒŒë¼ë¯¸í„° ì—…ë¡œë“œ ì™„ë£Œ! ({model_path})\")\n",
        "\n",
        "    # í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë” ìƒì„±\n",
        "    test_loader  = DataLoader(binary_test_ds,  batch_size=64, shuffle=False, num_workers=0, pin_memory=True)\n",
        "\n",
        "    # í‰ê°€ ì‹œì‘\n",
        "    best_model.eval()\n",
        "    test_correct, test_total = 0, 0\n",
        "    all_preds = []\n",
        "    with torch.no_grad():\n",
        "        for imgs, lbls in test_loader:\n",
        "            # ì›ë³¸ ì½”ë“œì˜ ì˜¤ë¥˜ ìˆ˜ì •: lblsë„ deviceë¡œ ì´ë™í•´ì•¼ í•©ë‹ˆë‹¤.\n",
        "            imgs, lbls = imgs.to(device), lbls.to(device)\n",
        "            \n",
        "            out = best_model(imgs)\n",
        "            pred = out.argmax(dim=1)\n",
        "            test_correct += (pred == lbls).sum().item()\n",
        "            test_total += lbls.size(0)\n",
        "            all_preds.extend(pred.cpu().numpy())\n",
        "\n",
        "    test_acc = test_correct / test_total * 100\n",
        "    print(\"=\"*40)\n",
        "    print(f\"ğŸ¯ ìµœì¢… ì¬í˜„ ì •í™•ë„ (0/6) = {test_acc:.4f}%\")\n",
        "    print(\"=\"*40)\n",
        "\n",
        "    # (ì„ íƒ ì‚¬í•­) ì œì¶œ íŒŒì¼ ìƒì„± ë¡œì§\n",
        "    best_preds = [0 if p == 0 else 6 for p in all_preds]\n",
        "    y_pred_full = np.zeros(len(test_ds), dtype=int)\n",
        "    y_pred_full[test_idx] = best_preds\n",
        "    print(f\"ì „ì²´ í…ŒìŠ¤íŠ¸ì…‹ ëŒ€ìƒ ì˜ˆì¸¡ ìƒì„± ì™„ë£Œ (ê¸¸ì´: {len(y_pred_full)})\")\n",
        "\n",
        "    # df = pd.DataFrame({\"y_pred\": y_pred_full})\n",
        "    # csv_name = os.path.join(base_path, f\"y_pred_{SEED}_reproduce.csv\")\n",
        "    # df.to_csv(csv_name, index=False, header=False)\n",
        "    # print(f\"ì œì¶œ íŒŒì¼ ì €ì¥ ì™„ë£Œ: {csv_name}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## [ë¶€ë¡] ëª¨ë¸ í•™ìŠµ ì½”ë“œ (ì°¸ê³ ìš©)\n",
        "\n",
        "ì•„ë˜ëŠ” `best_model.pth` íŒŒì¼ì„ ìƒì„±í•˜ëŠ” ë° ì‚¬ìš©ëœ í•™ìŠµ ì½”ë“œì…ë‹ˆë‹¤. (ì›ë³¸ ë…¸íŠ¸ë¶ ê¸°ì¤€ ì£¼ì„ ì²˜ë¦¬ëœ ë¶€ë¶„)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### A. í•™ìŠµìš© ë°ì´í„° ì¤€ë¹„ (ì›ë³¸)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# # ë°ì´í„° ë³€í™˜ ì •ì˜\n",
        "# transform_train = transforms.Compose([\n",
        "#     transforms.RandomRotation(15),\n",
        "#     transforms.RandomHorizontalFlip(),\n",
        "#     transforms.ToTensor(),\n",
        "#     transforms.Normalize((0.1307,), (0.3081,))\n",
        "# ])\n",
        "# transform_test = transforms.Compose([\n",
        "#     transforms.ToTensor(),\n",
        "#     transforms.Normalize((0.1307,), (0.3081,))\n",
        "# ])\n",
        "\n",
        "# # ë°ì´í„°ì…‹ ë¡œë“œ\n",
        "# train_ds = datasets.FashionMNIST(root=base_path, train=True, download=True, transform=transform_train)\n",
        "# test_ds = datasets.FashionMNIST(root=base_path, train=False, download=True, transform=transform_test)\n",
        "\n",
        "# # 0ê³¼ 6ë§Œ í•„í„°ë§\n",
        "# train_mask = (train_ds.targets == 0) | (train_ds.targets == 6)\n",
        "# test_mask  = (test_ds.targets  == 0) | (test_ds.targets  == 6)\n",
        "# train_idx  = torch.where(train_mask)[0]\n",
        "# test_idx   = torch.where(test_mask)[0]\n",
        "\n",
        "# # ë ˆì´ë¸” ì´ì§„í™”\n",
        "# train_ds.targets[train_ds.targets == 6] = 1\n",
        "# test_ds.targets[ test_ds.targets  == 6] = 1\n",
        "\n",
        "# # 0ê³¼ 6ë§Œ í¬í•¨ëœ ë°ì´í„°ì…‹\n",
        "# binary_train_ds = Subset(train_ds, train_idx)\n",
        "# binary_test_ds  = Subset(test_ds,  test_idx)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### B. í•™ìŠµ ë£¨í”„ (ì›ë³¸)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# # ë°ì´í„° ë¡œë” ì„¤ì •\n",
        "# train_loader = DataLoader(binary_train_ds, batch_size=64, shuffle=True,  num_workers=0, pin_memory=True)\n",
        "# test_loader  = DataLoader(binary_test_ds,  batch_size=64, shuffle=False, num_workers=0, pin_memory=True)\n",
        "\n",
        "# # ëª¨ë¸Â·ì˜µí‹°ë§ˆì´ì €Â·ìŠ¤ì¼€ì¤„ëŸ¬Â·ì†ì‹¤í•¨ìˆ˜ ì„¤ì •\n",
        "# model = HybridModel().to(device)\n",
        "# optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
        "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=10, factor=0.2)\n",
        "# criterion = nn.NLLLoss()\n",
        "\n",
        "# best_acc, epochs_no_improve = 0.0, 0\n",
        "# early_stopping_patience = 70\n",
        "# best_model_path   = os.path.join(base_path, f'best_model_seed_{SEED}.pth')\n",
        "\n",
        "# for epoch in range(800):\n",
        "#     model.train()\n",
        "#     total_loss, correct, total = 0, 0, 0\n",
        "#     for imgs, lbls in train_loader:\n",
        "#         imgs, lbls = imgs.to(device), lbls.to(device)\n",
        "#         optimizer.zero_grad()\n",
        "#         out = model(imgs)\n",
        "#         loss = criterion(out, lbls)\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "#         total_loss += loss.item()\n",
        "#         preds = out.argmax(dim=1)\n",
        "#         correct += (preds == lbls).sum().item()\n",
        "#         total += lbls.size(0)\n",
        "#     train_acc = correct / total\n",
        "#     scheduler.step(train_acc)\n",
        "#     if train_acc > best_acc:\n",
        "#         best_acc = train_acc\n",
        "#         epochs_no_improve = 0\n",
        "#         torch.save(model.state_dict(), best_model_path)\n",
        "#     else:\n",
        "#         epochs_no_improve += 1\n",
        "#         if epochs_no_improve >= early_stopping_patience:\n",
        "#             break\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
